
# Kaggle Competition

Here are the descriptions for each of your Kaggle competition projects:

---

### Titanic Survival Prediction
This project predicts the likelihood of survival for passengers aboard the Titanic using features such as age, gender, passenger class, and fare. The dataset was preprocessed for missing values, and various machine learning models, including Logistic Regression and Random Forest, were applied. The goal was to classify passengers into "Survived" or "Did not survive" categories.

- **Techniques**: Data preprocessing, feature engineering, logistic regression, random forest classification.
- **Evaluation Metric**: Accuracy, Confusion Matrix.

---

### Loan Default Prediction
In this project, the aim was to predict whether a borrower will default on their loan based on attributes like income, credit history, and loan amount. The solution is implemented using various binary classification algorithms, including Logistic Regression and Decision Trees. This project involved handling missing data and feature scaling.

- **Techniques**: Handling missing values, feature scaling, logistic regression, decision trees.
- **Evaluation Metric**: ROC-AUC, Accuracy.

---

### Home Price Prediction
This project focuses on predicting house prices using features like the number of rooms, location, area, and year of construction. The dataset was cleaned and prepared for model training, and regression techniques such as Linear Regression and Random Forest Regressor were used to estimate home prices.

- **Techniques**: Feature engineering, linear regression, random forest regressor.
- **Evaluation Metric**: Mean Squared Error (MSE), R-squared.

---

### Flight Price Prediction
This project predicts the price of flight tickets based on features such as airline, duration, layovers, and departure time. It applies regression algorithms to model the relationship between input features and flight price. The dataset underwent preprocessing, including handling categorical variables and scaling numerical values.

- **Techniques**: Data cleaning, feature transformation, regression models.
- **Evaluation Metric**: Root Mean Squared Error (RMSE), R-squared.

---

You can use these descriptions in your README files, and let me know if you need any further details or modifications!
## Run Locally

Clone the project

```bash
  git clone https://github.com/sush0677/Kaggle_Competation
```


## Installation

---
```bash
jupyter notebook
numpy
pandas
scikit-learn
matplotlib
seaborn
```


    
